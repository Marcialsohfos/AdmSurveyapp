import pytesseract
from PIL import Image
import cv2
import numpy as np
import pdf2image
import re
from typing import Dict, List, Any, Optional

class OCRProcessor:
 def __init__(self):
    # Configuration Tesseract pour Render/Linux
    try:
        # Sur Render, Tesseract est g√©n√©ralement dans le PATH
        # Teste si tesseract est disponible
        import subprocess
        result = subprocess.run(['which', 'tesseract'], capture_output=True, text=True)
        if result.stdout:
            print(f"‚úÖ Tesseract trouv√©: {result.stdout.strip()}")
        else:
            print("‚ö†Ô∏è Tesseract non trouv√© dans le PATH")
            # Essaye les chemins communs Linux
            possible_paths = [
                '/usr/bin/tesseract',
                '/usr/local/bin/tesseract',
                '/app/.apt/usr/bin/tesseract'
            ]
            for path in possible_paths:
                import os
                if os.path.exists(path):
                    pytesseract.pytesseract.tesseract_cmd = path
                    print(f"‚úÖ Tesseract configur√©: {path}")
                    break
    except Exception as e:
        print(f"‚ö†Ô∏è Configuration Tesseract √©chou√©e: {e}")
        # Continue sans configuration sp√©cifique
        
        # Parsers sp√©cialis√©s par type de contenu
        self.specialized_parsers = {
            'budget': self._parse_budget_data,
            'laboratoire': self._parse_lab_data,
            'rh_laboratoire': self._parse_rh_data,
            'voirie': self._parse_voirie_data,
            'formation': self._parse_formation_data,
            'tabular': self._parse_tabular_data_enhanced,
            'legal': self._parse_legal_data,
            'administrative': self._parse_administrative_data,
        }
        
        # D√©tecteurs automatiques de type
        self.content_detectors = [
            self._detect_budget,
            self._detect_formation,
            self._detect_tabular,
            self._detect_legal,
            self._detect_administrative,
            self._detect_rh_laboratoire
        ]
    
    def process_file(self, filepath: str, data_type: str = 'auto') -> Dict[str, Any]:
        """Traite le fichier avec d√©tection automatique ou manuelle du type"""
        # Extraction OCR
        text = self._extract_text(filepath)
        print(f"üìù Texte extrait ({len(text)} caract√®res)")
        
        # D√©tection automatique si demand√©
        if data_type == 'auto':
            detected_type = self._auto_detect_content_type(text)
            print(f"üîç Type d√©tect√©: {detected_type}")
            
            # Utiliser le parser tabulaire am√©lior√© si d√©tect√©
            if detected_type == 'tabular':
                parser = self._parse_tabular_data_enhanced
            else:
                parser = self.specialized_parsers.get(detected_type, self._parse_universal)
            data_type = detected_type
        else:
            # Utiliser le parser sp√©cifi√©
            if data_type == 'tabular':
                parser = self._parse_tabular_data_enhanced
            else:
                parser = self.specialized_parsers.get(data_type, self._parse_universal)
        
        # Parsing
        parsed_data = parser(text)
        parsed_data['detected_type'] = data_type
        parsed_data['raw_text_preview'] = text[:500] + '...' if len(text) > 500 else text
        
        # Log des r√©sultats
        if 'tables' in parsed_data:
            print(f"üìä Tableaux d√©tect√©s: {len(parsed_data['tables'])}")
            for i, table in enumerate(parsed_data['tables']):
                print(f"  - Tableau {i+1}: {table.get('row_count', 0)} lignes x {table.get('column_count', 0)} colonnes")
        
        return parsed_data
    
    def _auto_detect_content_type(self, text: str) -> str:
        """D√©tecte automatiquement le type de contenu"""
        scores = {}
        
        for detector in self.content_detectors:
            detector_name, score = detector(text)
            scores[detector_name] = score
        
        # Retourne le type avec le score le plus √©lev√©
        best_type = max(scores.items(), key=lambda x: x[1])[0]
        return best_type if scores[best_type] > 0 else 'universal'
    
    def _detect_budget(self, text: str) -> tuple:
        """D√©tecte les documents budg√©taires"""
        keywords = ['budget', 'montant', 'euro', '‚Ç¨', 'total', 'd√©pense', 'recette', 'solde', 'finance']
        score = sum(1 for kw in keywords if kw in text.lower())
        return 'budget', score
    
    def _detect_formation(self, text: str) -> tuple:
        """D√©tecte les documents de formation"""
        keywords = ['exercice', 'question', 'r√©ponse', '√©valuation', 'formation', 'apprentissage', 'examen', 'test']
        score = sum(1 for kw in keywords if kw in text.lower())
        return 'formation', score
    
    def _detect_tabular(self, text: str) -> tuple:
        """D√©tecte les donn√©es tabulaires"""
        # Compte les lignes avec des s√©parateurs tabulaires
        lines = text.split('\n')
        if not lines:
            return 'tabular', 0
            
        tabular_lines = sum(1 for line in lines 
                          if re.search(r'\s{2,}|\t|\|', line) and len(line.split()) >= 2)
        return 'tabular', tabular_lines / len(lines)
    
    def _detect_legal(self, text: str) -> tuple:
        """D√©tecte les documents juridiques"""
        keywords = ['article', 'loi', 'd√©cret', 'juridique', 'contrat', 'clause', 'legal', 'code']
        score = sum(1 for kw in keywords if kw in text.lower())
        return 'legal', score
    
    def _detect_administrative(self, text: str) -> tuple:
        """D√©tecte les documents administratifs g√©n√©riques"""
        keywords = ['r√©f√©rence', 'objet', 'destinataire', 'exp√©diteur', 'administration', 'document', 'officiel']
        score = sum(1 for kw in keywords if kw in text.lower())
        return 'administrative', score
    
    def _detect_rh_laboratoire(self, text: str) -> tuple:
        """D√©tecte les donn√©es RH de laboratoire"""
        keywords = ['technicien', 'atms', 'tms', 'tpms', 'itms', 'ims', 'effectif', 'grade', 'personnel', 'laboratoire']
        score = sum(1 for kw in keywords if kw in text.lower())
        return 'rh_laboratoire', score
    
    def _parse_universal(self, text: str) -> Dict[str, Any]:
        """
        Parser universel pour tout type de document
        Structure intelligente bas√©e sur l'analyse du contenu
        """
        # V√©rifier si du texte a √©t√© extrait
        if not text or text.strip() in ["Aucun texte d√©tect√© dans l'image", "Erreur lors de l'extraction OCR"]:
            return {
                'type': 'universal',
                'metadata': {'error': 'Aucun texte extrait'},
                'structure': {'error': 'OCR a √©chou√©'},
                'entities': {},
                'sections': [],
                'tables': [],
                'raw_text': text if text else 'Aucun texte extrait par OCR',
                'ocr_success': False
            }
        
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        
        return {
            'type': 'universal',
            'metadata': self._extract_metadata(text),
            'structure': self._analyze_document_structure(lines),
            'entities': self._extract_entities(text),
            'sections': self._extract_semantic_sections(lines),
            'tables': self._extract_tabular_data(lines),
            'raw_text': text,
            'ocr_success': True,
            'text_length': len(text),
            'line_count': len(lines)
        }
    
    def _parse_formation_data(self, text: str) -> Dict[str, Any]:
        """Parse les documents de formation/√©valuation structur√©s"""
        data = {
            'type': 'formation',
            'titre': '',
            'date': '',
            'exercices': [],
            'questions': [],
            'instructions': []
        }
        
        lines = text.split('\n')
        current_section = None
        current_exercice = None
        current_question = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # D√©tection du titre
            if 'INSTITUT' in line or 'MASTER' in line or 'FORMATION' in line:
                data['titre'] = line
                continue
                
            # D√©tection de la date
            date_match = re.search(r'(\d{1,2}\s+\w+\s+\d{4})', line)
            if date_match and not data['date']:
                data['date'] = date_match.group(1)
                
            # D√©tection des exercices
            if 'Exercice' in line or 'EXERCICE' in line:
                current_exercice = {
                    'titre': line,
                    'description': '',
                    'questions': []
                }
                data['exercices'].append(current_exercice)
                current_section = 'exercice'
                continue
                
            # D√©tection des questions (A., B., C., etc.)
            question_match = re.match(r'^([A-Z])\.\s*(.*)$', line)
            if question_match:
                current_question = {
                    'lettre': question_match.group(1),
                    'texte': question_match.group(2),
                    'instructions': []
                }
                if current_exercice:
                    current_exercice['questions'].append(current_question)
                else:
                    data['questions'].append(current_question)
                current_section = 'question'
                continue
                
            # D√©tection des instructions
            if 'Instructions' in line or 'INSTRUCTIONS' in line:
                current_section = 'instructions'
                continue
                
            # Ajout du contenu selon la section
            if current_section == 'exercice' and current_exercice:
                current_exercice['description'] += line + ' '
            elif current_section == 'question' and current_question:
                current_question['texte'] += ' ' + line
            elif current_section == 'instructions':
                data['instructions'].append(line)
            elif not current_section and len(line) > 10:
                # Texte g√©n√©ral
                data['instructions'].append(line)
        
        return data
    
    def _parse_tabular_data_enhanced(self, text: str) -> Dict[str, Any]:
        """Parse am√©lior√© pour les donn√©es tabulaires avec d√©tection de tableaux"""
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        
        data = {
            'type': 'tabular',
            'tables': [],
            'raw_data': [],
            'metadata': {}
        }
        
        current_table = []
        in_table = False
        table_start_index = -1
        
        for i, line in enumerate(lines):
            # D√©tection am√©lior√©e des tableaux
            if self._is_table_row(line):
                if not in_table:
                    in_table = True
                    current_table = []
                    table_start_index = i
                
                # Nettoyage et s√©paration des colonnes
                columns = self._split_table_columns(line)
                current_table.append(columns)
                
            else:
                if in_table:
                    # V√©rifier si c'est vraiment la fin du tableau
                    if (len(current_table) >= 2 and 
                        (i - table_start_index) > 5 and  # Tableau d'au moins 5 lignes
                        not self._is_possible_table_continuation(line, lines, i)):
                        
                        # Traiter le tableau complet
                        processed_table = self._process_table_data(current_table)
                        if processed_table:
                            data['tables'].append(processed_table)
                        
                        current_table = []
                        in_table = False
                        table_start_index = -1
                
                if line and not in_table:
                    data['raw_data'].append(line)
        
        # Traiter le dernier tableau si on est encore dedans
        if in_table and current_table:
            processed_table = self._process_table_data(current_table)
            if processed_table:
                data['tables'].append(processed_table)
        
        # Extraire les m√©tadonn√©es
        data['metadata'] = self._extract_tabular_metadata(text)
        
        return data
    
    def _is_table_row(self, line: str) -> bool:
        """D√©tecte si une ligne fait partie d'un tableau"""
        # V√©rifier la pr√©sence de s√©parateurs
        has_separators = re.search(r'\s{2,}|\t|\|', line)
        
        # V√©rifier le nombre de "colonnes" (mots s√©par√©s)
        words = re.split(r'\s{2,}|\t|\|', line)
        clean_words = [w.strip() for w in words if w.strip()]
        
        # Conditions pour √™tre une ligne de tableau
        return (has_separators and 
                len(clean_words) >= 2 and 
                not re.match(r'^[‚Ä¢\-*\u2022]', line) and  # Pas une puce
                len(line) < 200)  # Pas une ligne trop longue
    
    def _split_table_columns(self, line: str) -> List[str]:
        """S√©pare les colonnes d'une ligne de tableau"""
        # Essayer diff√©rents s√©parateurs
        separators = [r'\s{2,}', r'\t', r'\|']
        
        for sep in separators:
            if re.search(sep, line):
                columns = re.split(sep, line)
                # Nettoyer les colonnes
                clean_columns = [col.strip() for col in columns if col.strip()]
                if len(clean_columns) >= 2:
                    return clean_columns
        
        # Fallback: s√©paration par espace simple
        return [line.strip()]
    
    def _is_possible_table_continuation(self, line: str, all_lines: List[str], current_index: int) -> bool:
        """D√©termine si une ligne pourrait √™tre la continuation d'un tableau"""
        if not line.strip():
            return True
        
        # V√©rifier les motifs de continuation
        next_lines = all_lines[current_index:current_index + 3]
        table_like_count = sum(1 for l in next_lines if self._is_table_row(l))
        
        return table_like_count >= 2
    
    def _process_table_data(self, table_rows: List[List[str]]) -> Dict[str, Any]:
        """Traite les donn√©es brutes d'un tableau pour identifier en-t√™tes et donn√©es"""
        if not table_rows:
            return None
        
        # Identifier les en-t√™tes (premi√®re ligne avec des mots significatifs)
        potential_headers = table_rows[0]
        
        # V√©rifier si la premi√®re ligne semble √™tre un en-t√™te
        is_header = all(len(str(cell)) < 50 for cell in potential_headers) and len(potential_headers) >= 2
        
        if is_header and len(table_rows) > 1:
            headers = potential_headers
            rows = table_rows[1:]
        else:
            # G√©n√©rer des en-t√™tes automatiques
            headers = [f'Colonne_{i+1}' for i in range(len(table_rows[0]))]
            rows = table_rows
        
        return {
            'headers': headers,
            'rows': rows,
            'row_count': len(rows),
            'column_count': len(headers)
        }
    
    def _extract_tabular_metadata(self, text: str) -> Dict[str, Any]:
        """Extrait les m√©tadonn√©es sp√©cifiques aux documents tabulaires"""
        metadata = {
            'table_count': text.count('|') // 10,  # Estimation grossi√®re
            'numeric_values': re.findall(r'\b\d{2,}\b', text),  # Nombres √† 2+ chiffres
            'percentages': re.findall(r'\d+%', text),
            'dates': re.findall(r'\d{1,2}/\d{1,2}/\d{4}', text)
        }
        return metadata
    
    def _parse_rh_data(self, text: str) -> Dict[str, Any]:
        """Parser sp√©cifique pour les donn√©es RH de laboratoire"""
        data = {
            'type': 'rh_laboratoire',
            'personnel_par_grade': [],
            'statistiques': {},
            'observations': [],
            'tableaux': []
        }
        
        lines = text.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            
            # D√©tection des lignes de tableau RH
            if re.search(r'\b(ATMS|TMS|TPMS|ITMS|IMS|ASOL|Agent|Technicien|Ing√©nieur)\b', line, re.IGNORECASE):
                # Extraire grade et effectif
                grade_match = re.search(r'([A-Za-z\s\(\)]+)\s+(\d+)', line)
                if grade_match:
                    grade = grade_match.group(1).strip()
                    effectif = grade_match.group(2)
                    
                    data['personnel_par_grade'].append({
                        'grade': grade,
                        'effectif': effectif
                    })
            
            # D√©tection des pourcentages et statistiques
            elif '%' in line or 'pourcent' in line.lower():
                data['observations'].append(line)
            
            # D√©tection des totaux
            elif 'total' in line.lower() and any(c.isdigit() for c in line):
                data['observations'].append(line)
        
        # Extraire √©galement les tableaux standard
        tabular_data = self._parse_tabular_data_enhanced(text)
        data['tableaux'] = tabular_data.get('tables', [])
        
        # Calculer les totaux
        if data['personnel_par_grade']:
            try:
                total_effectif = sum(int(item['effectif']) for item in data['personnel_par_grade'] if item['effectif'].isdigit())
                data['statistiques']['total_effectif'] = total_effectif
                data['statistiques']['nombre_grades'] = len(data['personnel_par_grade'])
            except ValueError:
                data['statistiques']['total_effectif'] = 'Calcul impossible'
        
        return data

    def _parse_tabular_data(self, text: str) -> Dict[str, Any]:
        """Parse les donn√©es tabulaires (version originale)"""
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        
        data = {
            'type': 'tabular',
            'tables': [],
            'raw_data': []
        }
        
        current_table = []
        in_table = False
        
        for line in lines:
            # D√©tection des lignes tabulaires
            if re.search(r'\s{2,}|\t', line) and len(line.split()) >= 2:
                if not in_table:
                    in_table = True
                    current_table = []
                
                columns = re.split(r'\s{2,}|\t', line.strip())
                current_table.append(columns)
            else:
                if in_table and len(current_table) >= 1:
                    data['tables'].append({
                        'headers': current_table[0] if len(current_table) > 1 else ['Colonne'],
                        'rows': current_table[1:] if len(current_table) > 1 else current_table,
                        'row_count': len(current_table) - 1 if len(current_table) > 1 else len(current_table)
                    })
                    current_table = []
                    in_table = False
                
                if line:
                    data['raw_data'].append(line)
        
        # Ajouter le dernier tableau
        if in_table and current_table:
            data['tables'].append({
                'headers': current_table[0] if len(current_table) > 1 else ['Colonne'],
                'rows': current_table[1:] if len(current_table) > 1 else current_table,
                'row_count': len(current_table) - 1 if len(current_table) > 1 else len(current_table)
            })
        
        return data
    
    def _parse_legal_data(self, text: str) -> Dict[str, Any]:
        """Parse les documents juridiques"""
        data = {
            'type': 'legal',
            'articles': [],
            'sections': [],
            'references': []
        }
        
        lines = text.split('\n')
        current_article = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # D√©tection des articles
            article_match = re.match(r'^Article\s+(\d+)[:\s]*(.*)$', line, re.IGNORECASE)
            if article_match:
                if current_article:
                    data['articles'].append(current_article)
                current_article = {
                    'numero': article_match.group(1),
                    'titre': article_match.group(2).strip(),
                    'contenu': []
                }
                continue
            
            # D√©tection des sections
            section_match = re.match(r'^¬ß\s*(\d+)[:\s]*(.*)$', line)
            if section_match:
                data['sections'].append({
                    'numero': section_match.group(1),
                    'titre': section_match.group(2).strip()
                })
                continue
            
            # D√©tection des r√©f√©rences l√©gales
            if re.search(r'\b(loi|d√©cret|arr√™t√©|code)\s+n¬∞?\s*\d', line, re.IGNORECASE):
                data['references'].append(line)
                continue
            
            # Ajout au contenu de l'article courant
            if current_article and line:
                current_article['contenu'].append(line)
        
        # Ajouter le dernier article
        if current_article:
            data['articles'].append(current_article)
        
        return data
    
    def _parse_administrative_data(self, text: str) -> Dict[str, Any]:
        """Parse les documents administratifs"""
        data = {
            'type': 'administrative',
            'expediteur': '',
            'destinataire': '',
            'objet': '',
            'reference': '',
            'date': '',
            'contenu': []
        }
        
        lines = text.split('\n')
        in_header = True
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            if in_header:
                # D√©tection de l'exp√©diteur
                if not data['expediteur'] and any(mot in line.lower() for mot in ['de:', 'exp√©diteur:', 'from:']):
                    data['expediteur'] = line
                    continue
                
                # D√©tection du destinataire
                if not data['destinataire'] and any(mot in line.lower() for mot in ['√†:', 'destinataire:', 'to:']):
                    data['destinataire'] = line
                    continue
                
                # D√©tection de l'objet
                if not data['objet'] and any(mot in line.lower() for mot in ['objet:', 'sujet:', 'subject:']):
                    data['objet'] = line
                    continue
                
                # D√©tection de la r√©f√©rence
                if not data['reference'] and any(mot in line.lower() for mot in ['r√©f:', 'reference:', 'ref:']):
                    data['reference'] = line
                    continue
                
                # D√©tection de la date
                if not data['date'] and any(mot in line.lower() for mot in ['date:', 'le:']):
                    data['date'] = line
                    continue
                
                # Fin de l'en-t√™te quand on trouve du contenu substantiel
                if len(line) > 50 and not any(mot in line.lower() for mot in ['de:', '√†:', 'objet:', 'r√©f:', 'date:']):
                    in_header = False
            
            if not in_header:
                data['contenu'].append(line)
        
        return data

    def _parse_budget_data(self, text: str) -> Dict[str, Any]:
        """Parse les donn√©es de budget d'investissement"""
        data = {
            'type': 'budget',
            'lignes_budgetaires': [],
            'total': 0
        }
        
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Recherche de montants
            montant_match = re.search(r'(\d{1,3}(?:\s?\d{3})*(?:,\d+)?)\s*‚Ç¨?', line)
            if montant_match:
                ligne_data = {
                    'description': line,
                    'montant': self._parse_montant(montant_match.group(1))
                }
                data['lignes_budgetaires'].append(ligne_data)
                data['total'] += ligne_data['montant']
        
        return data
    
    def _parse_lab_data(self, text: str) -> Dict[str, Any]:
        """Parse les donn√©es de laboratoire"""
        data = {
            'type': 'laboratoire',
            'equipements': [],
            'personnel': []
        }
        
        lines = text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip().lower()
            
            if '√©quipement' in line or 'materiel' in line:
                current_section = 'equipements'
            elif 'personnel' in line or 'employ√©' in line:
                current_section = 'personnel'
            elif line and current_section:
                data[current_section].append(line)
        
        return data
    
    def _parse_voirie_data(self, text: str) -> Dict[str, Any]:
        """Parse les donn√©es de voirie"""
        data = {
            'type': 'voirie',
            'troncons': [],
            'infrastructures': []
        }
        
        lines = text.split('\n')
        for line in lines:
            if any(keyword in line.lower() for keyword in ['route', 'rue', 'avenue', 'boulevard']):
                troncon = {'description': line}
                
                # Patterns pour les donn√©es de voirie
                longueur_match = re.search(r'longueur[:\s]*(\d+(?:,\d+)?)\s*m', line.lower())
                if longueur_match:
                    troncon['longueur'] = longueur_match.group(1)
                
                largeur_match = re.search(r'largeur[:\s]*(\d+(?:,\d+)?)\s*m', line.lower())
                if largeur_match:
                    troncon['largeur'] = largeur_match.group(1)
                
                type_match = re.search(r'(route|rue|avenue|boulevard|chemin)', line.lower())
                if type_match:
                    troncon['type_voirie'] = type_match.group(1)
                
                data['troncons'].append(troncon)
        
        return data

    # M√âTHODES D'EXTRACTION ET PR√âTRAITEMENT
    def _extract_text(self, filepath: str) -> str:
        """Extrait le texte d'un fichier (PDF ou image) avec am√©liorations PDF"""
        if filepath.lower().endswith('.pdf'):
            try:
                print("üìÑ Traitement d'un fichier PDF...")
                
                # Essayer d'abord l'extraction texte directe
                try:
                    import PyPDF2
                    with open(filepath, 'rb') as file:
                        pdf_reader = PyPDF2.PdfReader(file)
                        text = ""
                        for page in pdf_reader.pages:
                            text += page.extract_text() + "\n"
                        
                        # Si l'extraction directe donne du texte valide, l'utiliser
                        if len(text.strip()) > 50:
                            print("‚úÖ Texte extrait directement du PDF")
                            return text
                except Exception as e:
                    print(f"‚ö†Ô∏è Extraction PDF directe √©chou√©e: {e}")
                
                # Fallback: conversion image + OCR
                print("üîÑ Conversion PDF en images pour OCR...")
                images = pdf2image.convert_from_path(filepath, dpi=300)  # Augmenter la r√©solution
                text = ""
                for i, image in enumerate(images):
                    print(f"üìÑ Traitement page {i+1}/{len(images)}")
                    page_text = self._extract_text_from_image(image)
                    text += f"--- Page {i+1} ---\n{page_text}\n\n"
                
                return text
                
            except Exception as e:
                print(f"‚ùå Erreur conversion PDF: {e}")
                return ""
        else:
            return self._extract_text_from_image(filepath)
    
    def _extract_text_from_image(self, image_path) -> str:
        """Extrait le texte d'une image avec pr√©traitement am√©lior√©"""
        try:
            # Charger l'image
            if isinstance(image_path, str):
                image = cv2.imread(image_path)
                if image is None:
                    return "Erreur: Impossible de charger l'image"
            else:
                image = cv2.cvtColor(np.array(image_path), cv2.COLOR_RGB2BGR)
            
            print(f"üìê Dimensions image: {image.shape}")
            
            # Redimensionner si trop petite (au moins 300px de hauteur)
            height, width = image.shape[:2]
            if height < 300:
                scale_factor = 300 / height
                new_width = int(width * scale_factor)
                image = cv2.resize(image, (new_width, 300), interpolation=cv2.INTER_CUBIC)
                print(f"üîÑ Image redimensionn√©e: {image.shape}")
            
            # Pr√©traitement am√©lior√©
            processed_image = self._preprocess_image_enhanced(image)
            
            # Configurations Tesseract √† essayer
            configs = [
                '--oem 3 --psm 6 -l fra+eng',  # Par d√©faut
                '--oem 3 --psm 3 -l fra+eng',  # Page enti√®re sans segmentation
                '--oem 3 --psm 4 -l fra+eng',  # Colonne unique de texte
                '--oem 3 --psm 8 -l fra+eng',  # Mot unique
                '--oem 3 --psm 11 -l fra+eng', # Sparse text
            ]
            
            best_text = ""
            best_config = ""
            
            for config in configs:
                try:
                    text = pytesseract.image_to_string(processed_image, config=config)
                    print(f"üîç Config {config}: {len(text.strip())} caract√®res")
                    
                    if len(text.strip()) > len(best_text.strip()):
                        best_text = text
                        best_config = config
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur config {config}: {e}")
                    continue
            
            print(f"‚úÖ Meilleure config: {best_config}")
            print(f"‚úÖ Texte extrait: {len(best_text)} caract√®res")
            
            if best_text.strip():
                return best_text
            else:
                # Essayer avec l'image originale en dernier recours
                try:
                    fallback_text = pytesseract.image_to_string(image, config='--oem 3 --psm 6 -l fra+eng')
                    print(f"üîÑ Fallback texte: {len(fallback_text.strip())} caract√®res")
                    return fallback_text
                except:
                    return "Aucun texte d√©tect√© dans l'image"
                
        except Exception as e:
            print(f"‚ùå Erreur extraction OCR: {e}")
            return f"Erreur lors de l'extraction OCR: {e}"
    
    def _preprocess_image_enhanced(self, image):
        """Am√©liore la qualit√© de l'image pour l'OCR avec plusieurs techniques"""
        try:
            # Convertir en niveaux de gris
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image
            
            # D√©noniser l'image
            denoised = cv2.medianBlur(gray, 3)
            
            # Plusieurs techniques de seuillage
            # 1. Seuillage adaptatif gaussien
            thresh1 = cv2.adaptiveThreshold(
                denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 11, 2
            )
            
            # 2. Seuillage d'Otsu
            _, thresh2 = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # 3. Am√©lioration du contraste
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            contrast_enhanced = clahe.apply(denoised)
            _, thresh3 = cv2.threshold(contrast_enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # Essayer les diff√©rentes versions et choisir la meilleure
            images_to_try = [thresh1, thresh2, thresh3, denoised]
            
            # Tester rapidement chaque version
            best_image = thresh1
            best_text_length = 0
            
            for img in images_to_try:
                try:
                    text = pytesseract.image_to_string(img, config='--oem 3 --psm 6 -l fra+eng')
                    if len(text.strip()) > best_text_length:
                        best_text_length = len(text.strip())
                        best_image = img
                except:
                    continue
            
            print(f"‚úÖ Texte d√©tect√©: {best_text_length} caract√®res")
            return best_image
            
        except Exception as e:
            print(f"‚ùå Erreur pr√©traitement image: {e}")
            return image

    def _preprocess_image(self, image):
        """Ancienne m√©thode de pr√©traitement (conserv√©e pour compatibilit√©)"""
        return self._preprocess_image_enhanced(image)
    
    def _parse_montant(self, montant_str: str) -> float:
        """Convertit une cha√Æne de montant en float"""
        try:
            clean = montant_str.replace(' ', '').replace(',', '.')
            return float(clean)
        except:
            return 0.0

    # M√âTHODES UNIVERSELES (n√©cessaires pour _parse_universal)
    def _extract_metadata(self, text: str) -> Dict[str, Any]:
        """Extrait les m√©tadonn√©es du document"""
        metadata = {
            'dates': re.findall(r'\d{1,2}/\d{1,2}/\d{4}|\d{1,2}\s+\w+\s+\d{4}', text),
            'amounts': re.findall(r'\d{1,3}(?:[ \.]\d{3})*(?:,\d+)?\s*‚Ç¨?', text),
            'emails': re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text),
            'urls': re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text),
        }
        return metadata
    
    def _analyze_document_structure(self, lines: List[str]) -> Dict[str, Any]:
        """Analyse la structure hi√©rarchique du document"""
        structure = {
            'title_levels': [],
            'paragraphs': [],
            'lists': [],
            'headings': []
        }
        
        for i, line in enumerate(lines):
            # D√©tection des titres
            if self._is_title(line, i, lines):
                level = self._determine_title_level(line)
                structure['title_levels'].append({
                    'text': line,
                    'level': level,
                    'position': i
                })
            
            # D√©tection des listes
            elif self._is_list_item(line):
                structure['lists'].append({
                    'text': line,
                    'position': i,
                    'type': 'ordered' if re.match(r'^\d+\.', line) else 'unordered'
                })
            
            # Paragraphes normaux
            elif len(line) > 20:
                structure['paragraphs'].append({
                    'text': line,
                    'position': i,
                    'length': len(line)
                })
        
        return structure
    
    def _is_title(self, line: str, index: int, all_lines: List[str]) -> bool:
        """D√©termine si une ligne est un titre"""
        if len(line) > 150:
            return False
        
        # Titres en majuscules
        if line.isupper() and len(line) > 5:
            return True
        
        # Titres avec formatage sp√©cifique
        title_patterns = [
            r'^[IVX]+\.',  # Chiffres romains
            r'^\d+\.',     # Chiffres arabes
            r'^[A-Z]\.',   # Lettres majuscules
            r'^¬ß',         # Paragraphe
            r'^Article',   # Article
        ]
        
        return any(re.match(pattern, line.strip()) for pattern in title_patterns)
    
    def _determine_title_level(self, line: str) -> int:
        """D√©termine le niveau hi√©rarchique d'un titre"""
        if line.isupper():
            return 1
        elif re.match(r'^[IVX]+\.', line):
            return 2
        elif re.match(r'^\d+\.', line):
            return 3
        elif re.match(r'^[a-z]\.', line):
            return 4
        else:
            return 5
    
    def _is_list_item(self, line: str) -> bool:
        """D√©termine si une ligne est un √©l√©ment de liste"""
        list_patterns = [
            r'^[‚Ä¢\-*\u2022]',  # Puces
            r'^\d+\.',         # Num√©rotation
            r'^[a-z]\)',       # Lettres minuscules
        ]
        return any(re.match(pattern, line.strip()) for pattern in list_patterns)
    
    def _extract_entities(self, text: str) -> Dict[str, List[str]]:
        """Extrait les entit√©s nomm√©es basiques"""
        entities = {
            'organizations': [],
            'locations': [],
            'dates': [],
            'amounts': []
        }
        
        # Organisations (mots en majuscules de plus de 2 caract√®res)
        organizations = re.findall(r'\b[A-Z][A-Z&]+\b', text)
        entities['organizations'] = list(set(org for org in organizations if len(org) > 2))
        
        # Localisations (mots avec capitale)
        locations = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', text)
        entities['locations'] = list(set(loc for loc in locations if len(loc.split()) <= 3))
        
        return entities
    
    def _extract_semantic_sections(self, lines: List[str]) -> List[Dict[str, Any]]:
        """Extrait les sections s√©mantiques du document"""
        sections = []
        current_section = []
        current_title = "Introduction"
        
        for line in lines:
            if self._is_title(line, 0, lines):  # Nouvelle section
                if current_section:
                    sections.append({
                        'title': current_title,
                        'content': current_section,
                        'word_count': sum(len(text.split()) for text in current_section)
                    })
                current_section = []
                current_title = line
            else:
                current_section.append(line)
        
        # Ajouter la derni√®re section
        if current_section:
            sections.append({
                'title': current_title,
                'content': current_section,
                'word_count': sum(len(text.split()) for text in current_section)
            })
        
        return sections
    
    def _extract_tabular_data(self, lines: List[str]) -> List[Dict[str, Any]]:
        """Extrait les donn√©es tabulaires"""
        tables = []
        current_table = []
        
        for line in lines:
            # D√©tection des lignes tabulaires (au moins 3 colonnes)
            if re.search(r'\s{2,}|\t', line) and len(line.split()) >= 3:
                columns = re.split(r'\s{2,}|\t', line.strip())
                current_table.append(columns)
            elif current_table:
                # Fin d'un tableau
                if len(current_table) >= 2:  # Au moins un en-t√™te et une ligne de donn√©es
                    tables.append({
                        'headers': current_table[0],
                        'rows': current_table[1:],
                        'row_count': len(current_table) - 1
                    })
                current_table = []
        
        return tables